Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job             count    min threads    max threads
------------  -------  -------------  -------------
all                 1              1              1
enriched_tfs        1              1              1
total               2              1              1

Select jobs to execute...

[Mon May 16 12:48:52 2022]
rule enriched_tfs:
    input: weights/wgEncodeSydhTfbsGm12878Nfe2hStdAlnRep0.10mers.svmw.txt
    output: expr_enriched_tfs.wgEncodeSydhTfbsGm12878Nfe2hStdAlnRep0.10mers.txt
    jobid: 1
    wildcards: sample=wgEncodeSydhTfbsGm12878Nfe2hStdAlnRep0, word_length=10
    resources: tmpdir=/tmp

[Mon May 16 12:48:52 2022]
Error in rule enriched_tfs:
    jobid: 1
    output: expr_enriched_tfs.wgEncodeSydhTfbsGm12878Nfe2hStdAlnRep0.10mers.txt

RuleException:
CalledProcessError in line 43 of /gpfs/scratch/jtl334/thesis/pipeline/workflow/Snakefile:
Command 'set -euo pipefail;  /gpfs/home/jtl334/.conda/envs/pipeline/bin/python3.7 /gpfs/scratch/jtl334/thesis/pipeline/.snakemake/scripts/tmpz0pjatve.count_kmers_per_motif.py' returned non-zero exit status 1.
  File "/gpfs/scratch/jtl334/thesis/pipeline/workflow/Snakefile", line 43, in __rule_enriched_tfs
  File "/gpfs/home/jtl334/.conda/envs/pipeline/lib/python3.7/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-05-16T124852.050546.snakemake.log
